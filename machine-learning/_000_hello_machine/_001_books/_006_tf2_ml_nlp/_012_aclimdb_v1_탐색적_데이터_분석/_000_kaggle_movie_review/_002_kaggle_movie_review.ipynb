{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "books/kaggle_movie_review.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "mount_file_id": "1Qpere5VQNPECQwuI5YWd8f-QsS0iigKH",
   "authorship_tag": "ABX9TyNQMhcjKNmBvVq/hhqULYOM",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/wiv33/A-Learning-python/blob/master/machine-learning/_000_hello_machine/_001_books/_006_tf2_ml_nlp/_012_aclimdb_v1_%ED%83%90%EC%83%89%EC%A0%81_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D/_000_kaggle_movie_review/_002_kaggle_movie_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Kaggle 대회 데이터 다운로드\n",
    "\n",
    "> 인증 토큰이 담긴 json 파일을 찾을 수 없다"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!kaggle competitions download -c word2vec-nlp-tutorial"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 선행\n",
    "\n",
    "* kaggle Account에서 token 생성\n",
    "* google drive에 추가\n",
    "* 파일을 `/root/.kaggle`로 이동"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!mkdir .kaggle\n",
    "!mv .kaggle /root/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!cp '/content/drive/My Drive/Colab Notebooks/auth/kaggle/kaggle.json' /root/.kaggle/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !cat /root/.kaggle/kaggle.json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!chmod 600 /root/.kaggle/kaggle.json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 버전 미스 매칭 확인"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!kaggle competitions download -c word2vec-nlp-tutorial"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip3 install --upgrade --force-reinstall --no-deps kaggle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 최신 버전 후 403 error"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!kaggle competitions download -c word2vec-nlp-tutorial"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 기존 버전 삭제 후 1.5.6 버전으로 다운로드"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip uninstall -y kaggle\n",
    "!pip install --upgrade pip\n",
    "!pip install kaggle==1.5.6\n",
    "!kaggle -v"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# content/ zip 파일 생성 확인\n",
    "\n",
    "    다운로드 위치 /content/\n",
    "    이후 drive로 이동하여 관리"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!kaggle competitions download -c word2vec-nlp-tutorial"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 다운로드 파일 압축 해제"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!unzip /content/*.zip"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 해제 후 data 디렉터리로 이동"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!mv /content/*.zip /content/*.csv '/content/drive/My Drive/Colab Notebooks/data/kaggle/movie_review/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# python 코드 시작"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "DATA_IN_PATH = '/content/drive/My Drive/Colab Notebooks/data/kaggle/movie_review/'\n",
    "\n",
    "file_list = ['labeledTrainData.tsv.zip', 'unlabeledTrainData.tsv.zip', 'testData.tsv.zip']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for f in file_list:\n",
    "  zipRef = zipfile.ZipFile(DATA_IN_PATH + f, 'r')\n",
    "  zipRef.extractall(DATA_IN_PATH)\n",
    "  zipRef.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline  # 그래프 바로 그리기"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 데이터 프레임으로 만들기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"{}labeledTrainData.tsv\".format(DATA_IN_PATH),\n",
    "                         header=0,\n",
    "                         delimiter='\\t', \n",
    "                         quoting=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 데이터 분석 순서\n",
    "\n",
    "1. 데이터 크기\n",
    "2. 데이터의 개수\n",
    "3. 각 리뷰의 문자 길이 분포\n",
    "4. 많이 사용된 단어\n",
    "5. 긍정, 부정 데이터의 분포\n",
    "6. 각 리뷰의 단어 개수 분포\n",
    "7. 특수문자 및 대문자, 소문자 비율"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. 데이터(파일)의 크기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"파일 크기 : \")\n",
    "for f in os.listdir(DATA_IN_PATH):\n",
    "  if 'tsv' in f and 'zip' not in f:\n",
    "    # print(f.ljust(30))\n",
    "    print(f.ljust(30) + str(round(os.path.getsize(DATA_IN_PATH + f) / 1000000, 2)) + \"MB\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"전체 학습 데이터 개수: {}\".format(len(train_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_length = train_data['review'].apply(len)\n",
    "train_length.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 주요 설정\n",
    "\n",
    "### 그래프 이미지 크기 설정\n",
    "\n",
    "* figsize: (가로, 세로) tuple"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 히스토그램\n",
    "\n",
    "* bins: 히스토그램 값 버킷 범위\n",
    "* range: x축 값의 범위\n",
    "* alpha: 그래프 색상 투명도\n",
    "* color: 그래프 색상\n",
    "* label: 그래프 라벨\n",
    "\n",
    "\n",
    "    ValueError: 'square' is not a valid value for scale; supported values are 'linear', 'log', 'symlog', 'logit', 'function', 'functionlog'\n",
    "\n",
    "\n",
    "* yscale 첫 번째 인자의 유효 값\n",
    "  - 'linear' \n",
    "  - 'log'\n",
    "  - 'symlog'\n",
    "  - 'logit'\n",
    "  - 'function'\n",
    "  - 'functionlog'\n",
    "    \n",
    "```python\n",
    "plt.yscale()\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 결과 내용\n",
    "\n",
    "    0 ~ 6000: 대부분의 데이터가 밀집한 상태\n",
    "    10000 이상: 이상치로 간주\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(train_length, \n",
    "         bins=200, \n",
    "         alpha=.5,\n",
    "         color='r',\n",
    "         label='word')\n",
    "\n",
    "# 로그의 크기를 가지도록 설정\n",
    "plt.yscale('log', nonposy='clip')\n",
    "\n",
    "plt.title('Log-Histogram of length of review')\n",
    "plt.xlabel('Length of review')\n",
    "plt.ylabel('Number of review')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 통곗값 확인"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 리뷰 길이 최댓값"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('리뷰 길이 최댓값: {}'.format(np.max(train_length)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('리뷰 길이 최솟값: {}'.format(np.min(train_length)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('리뷰 길이 평균값: {:.2f}'.format(np.mean(train_length)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('리뷰 길이 표준편차: {:.2f}'.format(np.std(train_length)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('리뷰 길이 중간값: {}'.format(np.max(train_length)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "    백분위 표시\n",
    "    -> 특정집단의 점수분포상에서 한 개인의 상대적 위치를 알수있는 유도점수\n",
    "    25는 25% 위치에 해당한 값\n",
    "    75는 75% 위치의 값\n",
    "    100% 값은 리뷰 길이 최댓값과 동일한 값\n",
    "\n",
    "- 사분위에 대한 경우는 0 ~ 100 스케일로 돼 있음"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('리뷰 길이 제1사분위: {}'.format(np.percentile(train_length, 25)))\n",
    "print('리뷰 길이 제3사분위: {}'.format(np.percentile(train_length, 75)))\n",
    "print('리뷰 길이 제4사분위: {}'.format(np.percentile(train_length, 100)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 박스 plot\n",
    "\n",
    "* 첫 번째 인자: 여러 분포에 대한 데이터 리스트 입력\n",
    "* labels: 입력한 데이터 라벨\n",
    "* showmeans: 평균값을 `마크`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.boxplot(train_length,\n",
    "            labels=['counts'],\n",
    "            showmeans=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 리뷰에서 많이 사용된 단어 확인\n",
    "\n",
    "### Word Cloud"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "cloud = WordCloud(width=800,\n",
    "                  height=600).generate(\" \".join(train_data['review']))\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.imshow(cloud)\n",
    "plt.axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 긍정, 부정 데이터 분포 확인\n",
    "\n",
    "### 씨본 (`seaborn`)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axe = plt.subplots(ncols=1)\n",
    "fig.set_size_inches(7, 4)\n",
    "sns.countplot(train_data['sentiment'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- sns.countplot()의 `argument` 확인하기\n",
    "  * 0과 1\n",
    "  * 각 숫자의 개수를 출력\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_data['sentiment'].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 각 라벨의 값 출력"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"긍정 리뷰 개수: {}\".format(train_data['sentiment'].value_counts()[1]))\n",
    "print(\"부정 리뷰 개수: {}\".format(train_data['sentiment'].value_counts()[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 단어 추출 - WordCloud\n",
    "\n",
    "- 띄어쓰기 기준으로 하나의 단어라고 가정"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_word_counts = train_data['review'].apply(lambda x: len(x.split(' ')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_word_counts.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.hist(train_word_counts,\n",
    "         bins=50, \n",
    "         facecolor='r',\n",
    "         label='train')\n",
    "plt.title(\"Log-Histogram of word count in review\",\n",
    "          fontsize=15)\n",
    "plt.yscale('log',\n",
    "           nonposy='clip'\n",
    "           )\n",
    "plt.legend()\n",
    "plt.xlabel('Number of words', fontsize=15)\n",
    "plt.ylabel('Number of reviews', fontsize=15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 통곗값 출력"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"리뷰 단어 개수 최댓값: {}\".format(np.max(train_word_counts)))\n",
    "print(\"리뷰 단어 개수 최솟값: {}\".format(np.min(train_word_counts)))\n",
    "print(\"리뷰 단어 개수 평균값: {:.2f}\".format(np.mean(train_word_counts)))\n",
    "print(\"리뷰 단어 개수 표준편차: {:.2f}\".format(np.std(train_word_counts)))\n",
    "print(\"리뷰 단어 개수 중간값: {}\".format(np.median(train_word_counts)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 사분위 (백분위)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('리뷰 단어 개수 제1사분위 : {}'.format(np.percentile(train_word_counts, 25)))\n",
    "print('리뷰 단어 개수 제3사분위 : {}'.format(np.percentile(train_word_counts, 75)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 각 리뷰의 구두점, 대소문자 비율"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_by_func(func):\n",
    "  return train_data['review'].apply(func)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mt(x):\n",
    "  return x * 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qmarks = np.mean(extract_by_func(lambda x: '?' in x))  # 물음표가 구두점으로 쓰임\n",
    "fullstop = np.mean(extract_by_func(lambda x: '.' in x))  # 마침표\n",
    "capital_first = np.mean(extract_by_func(lambda x: x[0].isupper()))  # 첫 번째 대문자\n",
    "capitals = np.mean(extract_by_func(lambda x: max([y.isupper() for y in x]))) # 대문자 개수\n",
    "numbers = np.mean(extract_by_func(lambda x: max([y.isdigit() for y in x]))) # 숫자 개수"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('물음표가 있는 질문: {:.2f}'.format(mt(qmarks)))\n",
    "print('마침표가 있는 질문: {:.2f}'.format(mt(fullstop)))\n",
    "print('첫 글자가 대문자인 질문: {:.2f}'.format(mt(capital_first)))\n",
    "print('대문자가 있는 질문: {:.2f}'.format(mt(capitals)))\n",
    "print('숫자가 있는 질문: {:.2f}'.format(mt(numbers)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 위 분석을 바탕으로 `전처리 시작`\n",
    "\n",
    "## 주요 패키지\n",
    "\n",
    "- ## json\n",
    "  \n",
    "- ## bs4.BeautifulSoup\n",
    "- ## nltk.corpus.stopwords\n",
    "- ## tensorflow.python.keras.preprocessing.sequence.pad_sequences\n",
    "- ## tensorflow.python.keras.preprocessing.txt.Tokenizer\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install nltk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 데이터 하나를 자세히 보기\n",
    "\n",
    "    전처리 방향성을 결정하기 위함"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATA_IN_PATH\n",
    "df_train_data = pd.read_csv(\"{}labeledTrainData.tsv\".format(DATA_IN_PATH), \n",
    "                            header=0,\n",
    "                            delimiter='\\t')\n",
    "df_train_data.iloc[0, 2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [전처리] HTML 태그, 특수문자 제거"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "review = df_train_data.iloc[0, 2]\n",
    "review_text = BeautifulSoup(review, 'lxml').get_text()\n",
    "review_text = re.sub('[^a-zA-Z]', ' ', review_text) # 영문자 제외, 모두 공백으로 변환"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "review_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [전처리] 불용어 제거\n",
    "\n",
    "    조사, 관사와 같은 어휘는\n",
    "    감정 분석에 영향을 미치지 않다고 판단하여\n",
    "    불용어에 포함시켰다.\n",
    "\n",
    "- ### 제거 방법\n",
    "  #### - 불용어로 정의한 사전을 이용\n",
    "  #### - (현재 기준)nltk 사전을 활용\n",
    "  #### - 모든 단어 소문자로 변경"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "영어 불용어 set 만들기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import nltk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "len(stop_words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## - [전처리] 소문자로 변경 후 불용어를 제거"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "review_text = review_text.lower()\n",
    "words = review_text.split()\n",
    "words = [w for w in words if not w in stop_words]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## - [전처리] 다시 하나의 글로 합친다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clean_review = ' '.join(words)\n",
    "clean_review"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 한 사이클의 전처리 과정을 모든 데이터에 반영할 함수 정의\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ps_preprocessing(review, remove_stopwords = False):\n",
    "  # 1. HTML 태그 제거\n",
    "  review_text = BeautifulSoup(review, 'lxml').get_text()\n",
    "\n",
    "  # 2. 영어가 아닌 특수문자를 공백으로 치환\n",
    "  review_text = re.sub('[^a-zA-Z]', ' ', review_text)\n",
    "\n",
    "  # 3. 대문자를 소문자로 바꾸고 공백 단위로 텍스트를 나누어 리스트로 만듦\n",
    "  words = review_text.lower().split()\n",
    "\n",
    "  # 3-1 불용어 제거하지 않을 경우 바로 반환\n",
    "  if not remove_stopwords:\n",
    "    return ' '.join(words)\n",
    "\n",
    "  # 4. 불용어 제거\n",
    "\n",
    "  # 영어 불용어 불러오기\n",
    "  stops = set(stopwords.words('english'))\n",
    "  # 불용어가 아닌 단어로 이뤄진 새로운 리스트 생성\n",
    "  words = [w for w in words if not w in stops]\n",
    "\n",
    "  # 5. 단어 리스트를 공백을 넣어서 하나의 글로 합친다.\n",
    "  return ' '.join(words)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clean_train_reviews = []\n",
    "for review in df_train_data['review']:\n",
    "  clean_train_reviews.append(ps_preprocessing(review, remove_stopwords=True))\n",
    "\n",
    "clean_train_reviews[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### * 전처리한 텍스트와 긍정 부정 값 매핑"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clean_train_df = pd.DataFrame(\n",
    "    {'review': clean_train_reviews, \n",
    "     'sentiment': df_train_data['sentiment']})\n",
    "\n",
    "clean_train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## - [전처리] 전처리한 데이터에서 각 단어를 `인덱스로 벡터화`\n",
    "\n",
    "    각 리뷰가 텍스트가 아닌 인덱스의 벡터로 구성될 것\n",
    "    각 인덱스가 어떤 단어를 의미하는지 확인할 수 있어야 한다.\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(clean_train_reviews)\n",
    "text_sequences = tokenizer.texts_to_sequences(clean_train_reviews)\n",
    "text_sequences[0][:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 단어 사전 확인하기\n",
    "\n",
    "    변환된 인덱스는 단어 사전을 통해 의미 확인\n",
    "    <PAD>는 padding을 의미\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "word_vocab = tokenizer.word_index\n",
    "word_vocab['<PAD>'] = 0\n",
    "# print(word_vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"전체 단어 개수: %d\" % len(word_vocab))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 단어 사전과 전체 단어 개수는 이후 모델에서 사용되기 때문에 저장한다."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_configs = {}\n",
    "data_configs['vocab'] = word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab) + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## - [전처리] 입력값의 길이를 동일하게 하는 `패딩`\n",
    "\n",
    "    1. 특정 길이를 최대 길이로 정하고\n",
    "    2. 초과하는 데이터의 뒷부분을 제거\n",
    "    3. 모자란 데이터의 경우 0을 ~~앞에서~~ **뒤에서** 채운다"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 174  # 문장 최대 길이\n",
    "train_inputs = pad_sequences(text_sequences, maxlen=MAX_SEQUENCE_LENGTH,\n",
    "                            #  padding='pre'\n",
    "                             padding='post'\n",
    "                             )\n",
    "print('Shape of train data : ', train_inputs.shape )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [전처리] 정답을 넘파이로 변환\n",
    "\n",
    "    이후 전처리한 데이터를 저장할 때 넘파이 형태로 저장"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_labels = np.array(train_data['sentiment'])\n",
    "print('Shape of label tensor: ', train_labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 데이터 전처리 흐름\n",
    "\n",
    "1. 원본 텍스트\n",
    "2. 인덱스 변환\n",
    "3. 사이즈 패딩\n",
    "4. 벡터화"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 전처리 데이터 저장\n",
    "\n",
    "- 정제된 텍스트 데이터: **CSV**\n",
    "- 벡터화한 데이터: **ndarray**\n",
    "- 정답 라벨: **ndarray**\n",
    "- 데이터 정보(단어 사전, 전체 단어 개수): **json**\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "REFINE = DATA_IN_PATH + \"refine/\"\n",
    "TRAIN_INPUT_DATA = 'train_input.npy'\n",
    "TRAIN_LABEL_DATA = 'train_label.npy'\n",
    "TRAIN_CLEAN_DATA = 'train_clean.csv'\n",
    "DATA_CONFIGS = 'data_configs.npy'\n",
    "\n",
    "if not os.path.exists(REFINE):\n",
    "  os.makedirs(REFINE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 전처리된 데이터를 넘파이 형태로 저장\n",
    "np.save(open(REFINE + TRAIN_INPUT_DATA, 'wb'), train_inputs)\n",
    "np.save(open(REFINE + TRAIN_LABEL_DATA, 'wb'), train_labels)\n",
    "\n",
    "# 정제된 텍스트를 CSV 형태로 저장\n",
    "clean_train_df.to_csv(REFINE + TRAIN_CLEAN_DATA, index=False)\n",
    "\n",
    "# 데이터 사전을 JSON 형태로 저장\n",
    "json.dump(data_configs, open(REFINE + DATA_CONFIGS, 'w'), ensure_ascii=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 평가(test)데이터 전처리\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 주의사항\n",
    "\n",
    "  학습 데이터 전처리 후 __평가 데이터 전처리 시__\n",
    "  학습 데이터에 적용한 토크나이저 객체를 계속 사용해야 인덱스가 같다.\n",
    "\n",
    "---\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_IN_PATH + \"testData.tsv\",\n",
    "                        header=0,\n",
    "                        delimiter='\\t',\n",
    "                        quoting=3)\n",
    "clean_test_reviews = []\n",
    "for review in test_data['review']:\n",
    "  clean_test_reviews.append(ps_preprocessing(review, remove_stopwords=True))\n",
    "\n",
    "clean_test_df = pd.DataFrame(\n",
    "    {'review': clean_test_reviews, \n",
    "     'id': test_data['id']}\n",
    "    )\n",
    "test_id = np.array(test_data['id'])\n",
    "\n",
    "tokenizer.fit_on_texts(clean_test_reviews)\n",
    "test_sequences = tokenizer.texts_to_sequences(clean_test_reviews)\n",
    "test_inputs = pad_sequences(test_sequences, \n",
    "                            maxlen=MAX_SEQUENCE_LENGTH, \n",
    "                            padding='post')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def refine(s) -> str:\n",
    "  return \"{}{}\".format(REFINE, s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TEST_INPUT_DATA = 'test_input.npy'\n",
    "TEST_CLEAN_DATA = 'test_clean.csv'\n",
    "TEST_ID_DATA = 'test_id.npy'\n",
    "\n",
    "np.save(open(refine(TEST_INPUT_DATA), 'wb'), test_inputs)\n",
    "np.save(open(refine(TEST_ID_DATA), 'wb'), test_id)\n",
    "clean_test_df.to_csv(refine(TEST_CLEAN_DATA), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 모델링 - 로지스틱 회귀"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "+ 전처리 이후 데이터 불러오기"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DATA_IN_PATH = '/content/drive/My Drive/Colab Notebooks/data/kaggle/movie_review/'\n",
    "TRAIN_CLEAN_DATA = 'train_clean.csv'\n",
    "\n",
    "train_data = pd.read_csv(refine(TRAIN_CLEAN_DATA), header=0, delimiter=',', quoting=3)\n",
    "\n",
    "reviews = list(train_data['review'])\n",
    "sentiments = list(train_data['sentiment'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "+ TF-IDF 벡터화\n",
    "\n",
    "  - TfidfVectorizer args\n",
    "\n",
    "      * ***min_df***\n",
    "        \n",
    "          설정 값보다 특정 토큰의 df 값이 더 적을 경우,\n",
    "\n",
    "          벡터화 과정에서 제거\n",
    "\n",
    "      * ***analyzer***\n",
    "          \n",
    "          `word`: 단어\n",
    "          \n",
    "          `char`: 한 문자\n",
    "\n",
    "      * ***sublinear_tf***\n",
    "\n",
    "          문서의 단어 빈도 수(Term frequency)에 대한 스무딩(smoothing) 여부 설정\n",
    "\n",
    "      * ***ngram_range***\n",
    "\n",
    "          빈도의 기본 단위 범위 설정\n",
    "\n",
    "      * ***max_features***\n",
    "\n",
    "          벡터의 최대 길이, 특징의 길이를 설정\n",
    "\n",
    "\n",
    "      "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=.0,\n",
    "                             analyzer='char', \n",
    "                             sublinear_tf=True,\n",
    "                             ngram_range=(1, 3),\n",
    "                             max_features=5000)\n",
    "\n",
    "X = vectorizer.fit_transform(reviews)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "+ 학습과 검증 데이터셋 분리\n",
    "\n",
    "  - sklearn.model_selection.train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 33\n",
    "TEST_SPLIT = .2\n",
    "\n",
    "y = np.array(sentiments)\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X, y,\n",
    "                                                    test_size=TEST_SPLIT, \n",
    "                                                    random_state=RANDOM_SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "+ 모델 선언 및 학습\n",
    "\n",
    "  - Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lgs = LogisticRegression(class_weight='balanced')\n",
    "lgs.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "+ 검증 데이터로 성능 평가\n",
    "\n",
    "  - accuracy: 정확도\n",
    "  - precision: 정밀도\n",
    "  - recall: 재현율\n",
    "  - 등."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Accuracy : {:f}'.format(lgs.score(X_eval, y_eval)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "+ submit 하기 위한 데이터 확인"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TEST_CLEAN_DATA = 'test_clean.csv'\n",
    "test_data = pd.read_csv(refine(TEST_CLEAN_DATA),\n",
    "                        header=0,\n",
    "                        delimiter=',', \n",
    "                        quoting=3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "+ TF-IDF 값으로 벡터화"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data_vecs = vectorizer.transform(test_data['review'])\n",
    "test_predicted = lgs.predict(test_data_vecs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_predicted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "+ 제출할 파일 생성"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATA_OUT_PATH = refine('data_out/')\n",
    "\n",
    "if not os.path.exists(DATA_OUT_PATH):\n",
    "  os.makedirs(DATA_OUT_PATH)\n",
    "\n",
    "ids = list(test_data['id'])\n",
    "answer_dataset = pd.DataFrame({'id': ids, 'sentiment': test_predicted})\n",
    "answer_dataset['id'] = answer_dataset['id'].apply(lambda x: x.replace('\"', ''))\n",
    "answer_dataset.to_csv(DATA_OUT_PATH + 'lgs_tfidf_answer.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATA_OUT_PATH"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "+ submit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c word2vec-nlp-tutorial -f '/content/drive/My Drive/Colab Notebooks/data/kaggle/movie_review/refine/data_out/lgs_tfidf_answer.csv' -m 'answer by tfidf'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## word2vec"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}