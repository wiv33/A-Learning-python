# fc to conv
"""
1. 다른 입력, 동일한 모델

14 x 14     ->  10 x 10     ->          5 x 5       -> 1 x 1        -> 1 x 1        -> 1 x 1
        (5, 5)          (2, 2) max pool         (5, 5)          (1, 1)          (1, 1)
    14 - 5 + 1          10 // 2              5 - 5 + 1       1 - 1 + 1       1 - 1 + 1

16 x 16     ->  12 x 12     ->          6 x 6       -> 2 x 2        -> 2 x 2        -> 2 x 2
        (5, 5)          (2, 2) max pool         (5, 5)          (1, 1)          (1, 1)
    16 - 5 + 1          12 // 2              6 - 5 + 1       2 - 1 + 1       2 - 1 + 1


두 네트워크는 동일함 (파라미터 수 동일)
입력, 출력의 width, height만 다름.

네트워크가 동일하다는 의미는 다양한 입력 사이즈에 대해 `재학습 없이` 동일한 convolution layer를 사용할 수 있다.

최근은 fc를 사용하지 않고 conv를 사용함.


2. feature 중첩
특성은 인접 cell과 중첩되 있고,
위치가 동일한 cell의 경우 예측도가 높아진다.


# yolo grid
you only look once
1.

32 x 32     ->      16 x 16     ->       8 x 8      ->      4 x 4       ->      2 x 2       ->      1 x 1 x 8 (5 + c)

최종적인 텐서는 (2 x 2) x 8
최종적인 텐서의 개수는 2 x 2, 4개의 피처가 들어갈 수 있는 영역을 지정할 수 있음.
4개 영역에 출력 결과를 넣고, 학습 및 추론 시 각 grid로 결과가 반영됨.

32 배수로 늘릴 수 있음.

224 x 224 -> 7 x 7 x 8
(입력)       (최종)

학습 시 center의 위치에 해당하는 cell에 결과를 입력.
-> 추론 시에 학습된 cell 쪽에 결과가 도출될 확률이 높아진다.

center의 좌표값 bx, by는 grid 좌상단 좌표의 offset으로 입력
-> grid 내의 cell 위치에 상대적으로 학습하게 됨으로서, `이동 대칭성이 확보됨.`

2. anchor box
opencv v4에서 사용하고 있음.

동시에 감지할 수 있는 최대 object 수

cell = 7 x 7, anchor = 2개, class = 3인 경우
->> 7 x 7 x 2 x (5 + 3) = 784개

cell = 19 x 19, anchor = 9개, class = 80인 경우
->> 19 x 19 x 9 x (5 + 80) = 3,249개


anchor 박스는 k-means clustering 으로 사전에 분류함.
small, medium, large 크기로 3개씩 총 9개.

3. yolo 출력 텐서 시각화
608 x 608 -> 19 x 19
grid의 크기 = 이미지 크기 / 32

"""
